{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Av-udXuAOvG2",
        "tbmELgiYRoRh",
        "qzAL6FcVR-cp",
        "cgRB5KuASgXh",
        "H18HXuuxSSw8",
        "cwMMJ8xt8CDh",
        "uryZBVhtbln4",
        "E45h2mp5VjP1",
        "HOBPog1wf-Fo"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import and install dependencies"
      ],
      "metadata": {
        "id": "Av-udXuAOvG2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ra3T7iLim-A",
        "outputId": "a331b9f2-6a55-452b-b212-3617b7b3cd53",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: scikit-network in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scikit-network) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from scikit-network) (1.13.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2\n",
        "!pip install scikit-network\n",
        "!pip install python-dotenv\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "import os\n",
        "import spacy\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "from bs4 import BeautifulSoup\n",
        "from dotenv import load_dotenv\n",
        "import matplotlib.pyplot as plt\n",
        "from calendar import monthrange\n",
        "from IPython.display import SVG\n",
        "from sknetwork.data import Bunch\n",
        "from sknetwork.ranking import PageRank\n",
        "from sknetwork.visualization import svg_graph\n",
        "from networkx.algorithms.community import greedy_modularity_communities"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using **The Guardian** API to Search for Recent Articles Related to a Subject (e.g., Bitcoin)\n",
        "\n",
        "The /search endpoint allows you to query articles with optional filters such as `tag` and `section` to refine your results.\n",
        "\n",
        "By default, you can use the **\"test\"** API key provided by The Guardian for experimentation and basic queries. However, if you plan to use this API for a project, it is highly recommended to sign up for your own API key to benefit from higher request limits and additional features.  \n",
        "\n",
        "Visit [The Guardian Developer website](https://open-platform.theguardian.com/) and register for a free API key.\n",
        "\n",
        "For more details on how to use this API effectively, refer to the [official documentation](https://open-platform.theguardian.com/documentation/).\n"
      ],
      "metadata": {
        "id": "tbmELgiYRoRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Search for tags associated with a given term using **The Guardian** API.  "
      ],
      "metadata": {
        "id": "qzAL6FcVR-cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_tags(term, api_key=\"test\"):\n",
        "    \"\"\"\n",
        "    Search for tags related to a specific term using The Guardian API.\n",
        "\n",
        "    Parameters:\n",
        "        term (str): The term to search for.\n",
        "        api_key (str): The API key for The Guardian API. Defaults to \"test\".\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tag IDs related to the term, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    base_url = \"https://content.guardianapis.com/tags\"\n",
        "    params = {\n",
        "        \"q\": term,\n",
        "        \"api-key\": api_key\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        tags_data = response.json()\n",
        "        if tags_data:\n",
        "            return [tag[\"id\"] for tag in tags_data[\"response\"][\"results\"]]\n",
        "\n",
        "        return []\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching tags: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "HE1UdkEjRNAU"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch the Latest Article URLs from **The Guardian** API based on a search term (`query`)\n",
        "\n"
      ],
      "metadata": {
        "id": "cgRB5KuASgXh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_latest_guardian_articles_urls(query, api_key=\"test\", page_size=10, tag=None, section=None):\n",
        "    \"\"\"\n",
        "    Fetch the latest article URLs related to a specific query from The Guardian API.\n",
        "\n",
        "    Parameters:\n",
        "        query (str): The term to search for.\n",
        "        api_key (str): The API key for The Guardian API. Defaults to \"test\".\n",
        "        page_size (int): Number of articles to return. Defaults to 10.\n",
        "        tag (str, optional): A tag to filter results (e.g., \"technology/bitcoin\").\n",
        "        section (str, optional): A section to filter results (e.g., \"economy\").\n",
        "\n",
        "    Returns:\n",
        "        list: A list of article URLs, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    base_url = \"https://content.guardianapis.com/search\"\n",
        "\n",
        "    params = {}\n",
        "\n",
        "    if section:\n",
        "      params[\"section\"] = section\n",
        "      #print(f\"Using section: {section}\")\n",
        "\n",
        "    if tag:\n",
        "      params[\"tag\"] = tag\n",
        "      #print(f\"Using tag: {tag}\")\n",
        "\n",
        "    params[\"order-by\"] = \"newest\"\n",
        "    params[\"page-size\"] = page_size\n",
        "    params[\"q\"] = query\n",
        "    params[\"api-key\"] = api_key\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        print(f\"Request URL: {response.url}\")\n",
        "\n",
        "        articles_data = response.json()\n",
        "        if articles_data and articles_data['response']['results']:\n",
        "            return [article[\"webUrl\"] for article in articles_data['response']['results']]\n",
        "\n",
        "        print(\"No articles found.\")\n",
        "        return []\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching articles: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "ATYywYT-St0j"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fetch the most relevante Article URLs from **The Guardian** API based on a search term (`query`) and a year\n",
        "\n"
      ],
      "metadata": {
        "id": "H18HXuuxSSw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_guardian_articles_urls_by_year(query, year, api_key=\"test\", page_size=10, tag=None, section=None):\n",
        "    \"\"\"\n",
        "    Fetch the most relevant article URLs for a specific query from The Guardian API within a given year.\n",
        "\n",
        "    Parameters:\n",
        "        query (str): The term to search for.\n",
        "        year (int): The year to filter results.\n",
        "        api_key (str): The API key for The Guardian API. Defaults to \"test\".\n",
        "        page_size (int): Number of articles to return per page. Defaults to 10.\n",
        "        tag (str, optional): A tag to filter results (e.g., \"technology/bitcoin\").\n",
        "        section (str, optional): A section to filter results (e.g., \"economy\").\n",
        "\n",
        "    Returns:\n",
        "        list: A list of article URLs, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    base_url = \"https://content.guardianapis.com/search\"\n",
        "\n",
        "    # Define the date range for the entire year\n",
        "    from_date = f\"{year}-01-01\"\n",
        "    to_date = f\"{year}-12-31\"\n",
        "\n",
        "    params = {}\n",
        "\n",
        "    if section:\n",
        "      params[\"section\"] = section\n",
        "      #print(f\"Using section: {section}\")\n",
        "\n",
        "    if tag:\n",
        "      params[\"tag\"] = tag\n",
        "      #print(f\"Using tag: {tag}\")\n",
        "\n",
        "    params[\"from-date\"] = from_date\n",
        "    params[\"to-date\"] = to_date\n",
        "    params[\"order-by\"] = \"newest\"\n",
        "    params[\"page-size\"] = page_size\n",
        "    params[\"q\"] = query\n",
        "    params[\"api-key\"] = api_key\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        print(f\"Request URL: {response.url}\")\n",
        "\n",
        "        articles_data = response.json()\n",
        "        if articles_data and articles_data['response']['results']:\n",
        "            return [article[\"webUrl\"] for article in articles_data['response']['results']]\n",
        "\n",
        "        print(\"No articles found.\")\n",
        "        return []\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching articles: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "4HO1Wp_IRfRg"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using **NewsAPI** to Search for Articles Related to a Subject (e.g., Bitcoin)\n",
        "\n",
        "The `/everything` endpoint of NewsAPI allows you to query articles with filters like `language`, `sortBy`, and `pageSize` to refine your results. You will need to get a **free API key**.\n",
        "\n",
        "Visit [NewsAPI's website](https://newsapi.org/) to register for a free API key.\n",
        "\n",
        "For detailed documentation, visit the [official NewsAPI documentation](https://newsapi.org/docs/endpoints/everything).\n"
      ],
      "metadata": {
        "id": "cwMMJ8xt8CDh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_newsapi_articles_urls_by_year(query, api_key, language=\"en\", page_size=10):\n",
        "    \"\"\"\n",
        "    Fetch the latest article URLs related to a specific query from NewsAPI.\n",
        "\n",
        "    Parâmetros:\n",
        "        query (str): The term to search for\n",
        "        api_key (str): Chave de API para autenticação na NewsAPI.\n",
        "        language (str): Idioma das notícias (padrão: \"en\").\n",
        "        page_size (int): Número de artigos a retornar (máx. 100).\n",
        "\n",
        "    Retorna:\n",
        "        list: Lista de URLs de artigos sobre Bitcoin.\n",
        "    \"\"\"\n",
        "    url = \"https://newsapi.org/v2/everything\"\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"language\": language,\n",
        "        \"pageSize\": page_size,\n",
        "        \"sortBy\": \"relevancy\",\n",
        "        \"apiKey\": api_key\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        print(f\"Request URL: {response.url}\")\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        if \"articles\" in data:\n",
        "          return [article[\"url\"] for article in data[\"articles\"]]\n",
        "        else:\n",
        "          print(\"No articles found.\")\n",
        "          return []\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching articles: {e}\")\n",
        "        return []\n"
      ],
      "metadata": {
        "id": "NWK4N4s77aNV"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using spaCy and Natural Language Toolkit (NLTK) to Process Articles from HTML Pages\n",
        "\n",
        "This section demonstrates how to use **spaCy** and **NLTK** to process and analyze the content of articles retrieved using **The Guardian API**.  \n",
        "\n",
        "#### Overview:\n",
        "\n",
        "1. Text Extraction: parse the HTML obtained from The Guardian API URLs to extract the main article text.\n",
        "2. Natural Language Processing (NLP):\n",
        "   - **spaCy** used for tokenization, named entity recognition (NER), and part-of-speech (POS) tagging.\n",
        "   - **NLTK** used for part-of-speech (POS) tagging."
      ],
      "metadata": {
        "id": "uryZBVhtbln4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HTML parse and cleaning text article from given a given URL"
      ],
      "metadata": {
        "id": "E45h2mp5VjP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_article_text(url):\n",
        "    \"\"\"\n",
        "    Fetches and extracts the article text from a given URL.\n",
        "\n",
        "    Parameters:\n",
        "        url (str): The URL of the article to extract text from.\n",
        "\n",
        "    Returns:\n",
        "        str: The text content of the article, or None if an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raises an HTTPError for bad responses (4xx, 5xx)\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Only match <article> tag to get the main content\n",
        "        article = soup.find('article')\n",
        "        if not article:\n",
        "            print(f\"No <article> tag found for URL: {url}\")\n",
        "            return None\n",
        "\n",
        "        # Find all relevant text elements (<p> for paragraphs, <h1>-<h6> for headings)\n",
        "        tags = article.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
        "\n",
        "        # Extract text and join it into a single string\n",
        "        text = ''.join(tag.get_text(strip=True).rstrip('.\\n') + \".\\n\" for tag in tags)\n",
        "\n",
        "        return text\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error processing URL {url}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "ePqVsg8kdtkp"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using only spaCy for tokenization, named entity recognition (NER), and part-of-speech (POS) tagging."
      ],
      "metadata": {
        "id": "iBwJu_qCemQA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text_with_spacy(text):\n",
        "    \"\"\"\n",
        "    Processes the given text using spaCy for tokenization, part-of-speech tagging,\n",
        "    and named entity recognition (NER).\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The text to process.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing two elements:\n",
        "            - A list of proper noun tags (tokens with tag 'NNP').\n",
        "            - A list of filtered named entities (PERSON, ORG, GPE).\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "\n",
        "    sentences = list(doc.sents)\n",
        "\n",
        "    entities = []\n",
        "    nnp_tags = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "\n",
        "      for token in sentence:\n",
        "        if token.tag_ == 'NNP' and token.text.isalpha():\n",
        "          nnp_tags.append(token.text)\n",
        "\n",
        "      sentence_entities = []\n",
        "\n",
        "      sent_doc = nlp(sentence.text)\n",
        "      for ent in sent_doc.ents:\n",
        "        if ent.label_ in ['PERSON', 'ORG', 'GPE']:\n",
        "          entity = ent.text.strip()\n",
        "\n",
        "          if \"'s\" in entity:\n",
        "\n",
        "              cutoff = entity.index(\"'s\")\n",
        "\n",
        "              entity = entity[:cutoff]\n",
        "\n",
        "          if entity != '':\n",
        "\n",
        "              sentence_entities.append(entity)\n",
        "\n",
        "        sentence_entities = list(set(sentence_entities))\n",
        "\n",
        "        if len(sentence_entities) > 1:\n",
        "\n",
        "            entities.append(sentence_entities)\n",
        "\n",
        "    return nnp_tags, entities"
      ],
      "metadata": {
        "id": "9xTQ8nDXyHdg"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using spaCy and NLTK for tokenization, named entity recognition (NER), and part-of-speech (POS) tagging."
      ],
      "metadata": {
        "id": "U6Nf9jMVev0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text_with_nltk_and_spacy(text):\n",
        "    \"\"\"\n",
        "    Process the given text using both NLTK and spaCy for tokenization,\n",
        "    part-of-speech tagging, and named entity recognition (NER).\n",
        "\n",
        "    Parameters:\n",
        "        text (str): The text to be processed.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - A list of proper nouns (NNP) from POS tagging using NLTK.\n",
        "            - A list of filtered named entities (PERSON, ORG, GPE) using spaCy.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        #NLTK\n",
        "        sentences = nltk.sent_tokenize(text)\n",
        "\n",
        "        pos_tags = []\n",
        "        for sentence in sentences:\n",
        "            words = nltk.word_tokenize(sentence)\n",
        "            pos_tags.extend(nltk.pos_tag(words))\n",
        "\n",
        "        nnp_tags = [tag for tag in pos_tags if tag[1] == 'NNP' and tag[0].isalpha()]\n",
        "\n",
        "        #spaCy\n",
        "        doc = nlp(text)\n",
        "\n",
        "        sentences = list(doc.sents)\n",
        "\n",
        "        entities = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "          sentence_entities = []\n",
        "\n",
        "          sent_doc = nlp(sentence.text)\n",
        "          for ent in sent_doc.ents:\n",
        "            if ent.label_ in ['PERSON', 'ORG', 'GPE']:\n",
        "              entity = ent.text.strip()\n",
        "\n",
        "              if \"'s\" in entity:\n",
        "\n",
        "                  cutoff = entity.index(\"'s\")\n",
        "\n",
        "                  entity = entity[:cutoff]\n",
        "\n",
        "              if entity != '':\n",
        "\n",
        "                  sentence_entities.append(entity)\n",
        "\n",
        "            sentence_entities = list(set(sentence_entities))\n",
        "\n",
        "            if len(sentence_entities) > 1:\n",
        "\n",
        "                entities.append(sentence_entities)\n",
        "\n",
        "        return nnp_tags, entities\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text: {e}\")\n",
        "        return [], []\n"
      ],
      "metadata": {
        "id": "VX4CBKo970l-"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting entities into network data\n"
      ],
      "metadata": {
        "id": "HOBPog1wf-Fo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract entities from articles_urls texts"
      ],
      "metadata": {
        "id": "E7l1YWypKa38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_entities(articles_urls, print_all=False):\n",
        "    \"\"\"\n",
        "    Extracts named entities related to theme from a list of article URLs.\n",
        "\n",
        "    Parameters:\n",
        "        articles_urls (list of str): List of URLs to process.\n",
        "        print_all (bool): If True, prints URLs, entities and NNP Tags.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of named entities extracted from the articles.\n",
        "    \"\"\"\n",
        "    entities = []\n",
        "\n",
        "    for url in articles_urls:\n",
        "        text = get_article_text(url)\n",
        "\n",
        "        if print_all:\n",
        "            print(f\"URL: {url}\")\n",
        "\n",
        "        if text:\n",
        "            #nnp_tags, article_entities = process_text_with_nltk_and_spacy(text)\n",
        "            nnp_tags, article_entities = process_text_with_spacy(text)\n",
        "            entities.extend(article_entities)\n",
        "\n",
        "            if print_all:\n",
        "                print(\"NNP Tags (Proper Nouns):\", nnp_tags)\n",
        "                print(f\"Filtered Named Entities (PERSON, ORG, GPE): {article_entities}\\n\")\n",
        "\n",
        "    return entities"
      ],
      "metadata": {
        "id": "5YR2QPamKZSo"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get network data from entities"
      ],
      "metadata": {
        "id": "rql3opC2MQPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_network_data(entities):\n",
        "\n",
        "    final_sources = []\n",
        "    final_targets = []\n",
        "\n",
        "    for row in entities:\n",
        "\n",
        "        source = row[0]\n",
        "        targets = row[1:]\n",
        "\n",
        "        for target in targets:\n",
        "\n",
        "            final_sources.append(source)\n",
        "            final_targets.append(target)\n",
        "\n",
        "    df = pd.DataFrame({'source':final_sources, 'target':final_targets})\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "R7GonV0hL-zc"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Draw networkx graphs from network data"
      ],
      "metadata": {
        "id": "3gld6PBaPQOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_graph(G, show_names=False, node_size=1, font_size=10, edge_width=0.5, file_path=None):\n",
        "\n",
        "    adjacency = nx.adjacency_matrix(G, weight='weight')\n",
        "    adjacency = sp.csr_matrix(adjacency)\n",
        "\n",
        "    names = np.array(list(G.nodes()))\n",
        "\n",
        "    graph = Bunch()\n",
        "    graph.adjacency = adjacency\n",
        "    graph.names = np.array(names)\n",
        "\n",
        "    pagerank = PageRank()\n",
        "\n",
        "    pagerank.fit(adjacency)\n",
        "    scores = pagerank.scores_\n",
        "\n",
        "    if show_names:\n",
        "\n",
        "        image = svg_graph(graph.adjacency, font_size=font_size, node_size=node_size, names=graph.names, width=700, height=500, scores=scores, edge_width=edge_width)\n",
        "\n",
        "    else:\n",
        "\n",
        "        image = svg_graph(graph.adjacency, node_size=node_size, width=700, height=500, scores = scores, edge_width=edge_width)\n",
        "\n",
        "    if file_path:\n",
        "        with open(file_path, 'w') as f:\n",
        "            f.write(image)\n",
        "\n",
        "    return SVG(image)"
      ],
      "metadata": {
        "id": "Imr9fk0zPYDb"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_ego_graph(G, ego, center=True, k=0, show_names=True, edge_width=0.1, node_size=3, font_size=12, file_path=None):\n",
        "\n",
        "    G.remove_edges_from(nx.selfloop_edges(G))\n",
        "\n",
        "    ego = nx.ego_graph(G, ego, center=center)\n",
        "\n",
        "    ego = nx.k_core(ego, k)\n",
        "\n",
        "    return draw_graph(ego, node_size=node_size, font_size=font_size, show_names=show_names, edge_width=edge_width, file_path=file_path)"
      ],
      "metadata": {
        "id": "TSI9PLESRFZQ"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure environment, set query and apply functions to get graph and metrics"
      ],
      "metadata": {
        "id": "ctk7SlvYNhjX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the 100 newest articles from The Guardian api"
      ],
      "metadata": {
        "id": "D8tbuvqBMiYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"THE_GUARDIAN_API_KEY\", \"test\")\n",
        "\n",
        "query = \"Bitcoin\"\n",
        "\n",
        "tag = search_tags(query, api_key)[0]"
      ],
      "metadata": {
        "id": "pKCGb5wL_Biw"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_guardian_articles_urls = get_latest_guardian_articles_urls(query, api_key, page_size=100, tag=tag, section=None)\n",
        "\n",
        "print(f\"Número de artigos utilizados: {len(the_guardian_articles_urls)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DyNRdeeIQUh",
        "outputId": "9842f42a-214d-4572-8a57-2d6079476581"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request URL: https://content.guardianapis.com/search?tag=technology%2Fbitcoin&order-by=newest&page-size=100&q=Bitcoin&api-key=test\n",
            "Número de artigos utilizados: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "the_guardian_bitcoin_entities = extract_entities(the_guardian_articles_urls, print_all=False)"
      ],
      "metadata": {
        "id": "DDKOftCdMcXw"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_guardian_bitcoin_network_df = get_network_data(the_guardian_bitcoin_entities)\n",
        "\n",
        "G_the_guardian_bitcoin = nx.from_pandas_edgelist(the_guardian_bitcoin_network_df)\n",
        "\n",
        "G_the_guardian_bitcoin.remove_edges_from(nx.selfloop_edges(G_the_guardian_bitcoin))"
      ],
      "metadata": {
        "id": "m5yGS9eJO4xJ"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(G_the_guardian_bitcoin)\n",
        "print(tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PugDr_ezDeBz",
        "outputId": "1454bcee-116a-488c-ce39-bcacf3411571"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph with 1186 nodes and 1732 edges\n",
            "technology/bitcoin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "draw_ego_graph(G_the_guardian_bitcoin, 'Bitcoin', file_path=\"latest_ego_bitcoin_graph.svg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "2B6BSwg9Aj4M",
        "outputId": "f8410576-e605-4353-c9df-1a0ff0877ea8"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"919.7854350582\" height=\"540\">\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 399 520 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 359 392 399 520\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 20 283 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 269 236 238 172\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 269 236 359 392\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 269 236 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 603 83 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 482 411 359 392\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 482 411 382 442\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 482 411 367 321\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 482 411 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 124 371 248 358\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 124 371 101 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 124 371 155 467\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 124 371 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 382 442 248 358\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 382 442 359 392\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 382 442 482 411\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 359 392 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 359 392 367 321\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 359 392 382 442\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 359 392 482 411\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 248 358 382 442\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 248 358 367 321\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 248 358 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 259 430 359 392\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 259 430 367 321\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 259 430 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 515 205 367 321\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 515 205 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 382 442 367 321\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 93 137 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 720 327 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 596 485 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 238 172 269 236\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 238 172 367 321\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 238 172 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 496 36 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 359 392 259 430\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 359 392 269 236\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 720 327 707 254\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 382 442 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 687 156 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 367 321 248 358\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 496 36\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 359 392\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 20 283\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 269 236\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 603 83\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 482 411\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 124 371\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 382 442\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 238 172\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 687 156\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 707 254\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 640 379\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 101 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 155 467\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 301 20\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 399 520\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 301 20 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 399 520 359 392\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 367 321\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 248 358 124 371\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 596 485\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 93 137\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 367 321 259 430\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 367 321 515 205\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 367 321 238 172\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 367 321 359 392\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 367 321 482 411\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 367 321 382 442\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 367 321 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 707 254 720 327\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 720 327\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 707 254 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 101 273 124 371\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 101 273 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 155 467 124 371\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 155 467 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 372 66\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 248 358\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 259 430\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 393 273 515 205\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 640 379 393 273\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 372 66 393 273\"/>\n<circle cx=\"399\" cy=\"520\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"301\" cy=\"20\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"393\" cy=\"273\" r=\"3.0\" style=\"fill:rgb(179, 3, 38);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"155\" cy=\"467\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"101\" cy=\"273\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"640\" cy=\"379\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"707\" cy=\"254\" r=\"3.0\" style=\"fill:rgb(70, 93, 207);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"367\" cy=\"321\" r=\"3.0\" style=\"fill:rgb(138, 173, 253);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"687\" cy=\"156\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"382\" cy=\"442\" r=\"3.0\" style=\"fill:rgb(99, 131, 234);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"124\" cy=\"371\" r=\"3.0\" style=\"fill:rgb(92, 123, 229);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"482\" cy=\"411\" r=\"3.0\" style=\"fill:rgb(88, 118, 226);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"603\" cy=\"83\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"269\" cy=\"236\" r=\"3.0\" style=\"fill:rgb(80, 107, 218);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"20\" cy=\"283\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"359\" cy=\"392\" r=\"3.0\" style=\"fill:rgb(127, 162, 250);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"496\" cy=\"36\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"238\" cy=\"172\" r=\"3.0\" style=\"fill:rgb(80, 107, 218);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"596\" cy=\"485\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"720\" cy=\"327\" r=\"3.0\" style=\"fill:rgb(70, 93, 207);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"93\" cy=\"137\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"515\" cy=\"205\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"259\" cy=\"430\" r=\"3.0\" style=\"fill:rgb(76, 102, 214);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"248\" cy=\"358\" r=\"3.0\" style=\"fill:rgb(88, 118, 226);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"372\" cy=\"66\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<text text-anchor=\"start\" x=\"405\" y=\"520\" font-size=\"12\">reserve”of</text><text text-anchor=\"start\" x=\"307\" y=\"20\" font-size=\"12\">Sam Bankman-Friedcommitted</text><text text-anchor=\"start\" x=\"399\" y=\"273\" font-size=\"12\">Bitcoin</text><text text-anchor=\"start\" x=\"161\" y=\"467\" font-size=\"12\">Kanye West</text><text text-anchor=\"start\" x=\"107\" y=\"273\" font-size=\"12\">Bill Gates</text><text text-anchor=\"start\" x=\"646\" y=\"379\" font-size=\"12\">Barack Obama</text><text text-anchor=\"start\" x=\"713\" y=\"254\" font-size=\"12\">Satoshi Nakamoto</text><text text-anchor=\"start\" x=\"373\" y=\"321\" font-size=\"12\">US</text><text text-anchor=\"start\" x=\"693\" y=\"156\" font-size=\"12\">David Gerard</text><text text-anchor=\"start\" x=\"388\" y=\"442\" font-size=\"12\">Donald Trump</text><text text-anchor=\"start\" x=\"130\" y=\"371\" font-size=\"12\">Joseph James O’Connor</text><text text-anchor=\"start\" x=\"488\" y=\"411\" font-size=\"12\">Robert F Kennedy Jr</text><text text-anchor=\"start\" x=\"609\" y=\"83\" font-size=\"12\">Gurvais Grigg</text><text text-anchor=\"start\" x=\"275\" y=\"236\" font-size=\"12\">Tether</text><text text-anchor=\"start\" x=\"26\" y=\"283\" font-size=\"12\">Monero</text><text text-anchor=\"start\" x=\"365\" y=\"392\" font-size=\"12\">Trump</text><text text-anchor=\"start\" x=\"502\" y=\"36\" font-size=\"12\">Morgan</text><text text-anchor=\"start\" x=\"244\" y=\"172\" font-size=\"12\">UK</text><text text-anchor=\"start\" x=\"602\" y=\"485\" font-size=\"12\">Binance boss</text><text text-anchor=\"start\" x=\"726\" y=\"327\" font-size=\"12\">authorof</text><text text-anchor=\"start\" x=\"99\" y=\"137\" font-size=\"12\">US Securities and Exchange Commission</text><text text-anchor=\"start\" x=\"521\" y=\"205\" font-size=\"12\">Celsius</text><text text-anchor=\"start\" x=\"265\" y=\"430\" font-size=\"12\">America</text><text text-anchor=\"start\" x=\"254\" y=\"358\" font-size=\"12\">Apple</text><text text-anchor=\"start\" x=\"378\" y=\"66\" font-size=\"12\">Brosens</text></svg>"
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing graph using the most relevant articles of a year (2018) from The Guardian api"
      ],
      "metadata": {
        "id": "7WsYSJzfOOCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "the_guardian_2018_bitcoin_articles_url = get_guardian_articles_urls_by_year(query, 2018, api_key, page_size=100, tag=tag, section=None)\n",
        "\n",
        "print(f\"Número de artigos utilizados: {len(the_guardian_2018_bitcoin_articles_url)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5elRRnzULJAn",
        "outputId": "9181b6f6-d161-4f36-bea7-74a2392d769a"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request URL: https://content.guardianapis.com/search?tag=technology%2Fbitcoin&from-date=2018-01-01&to-date=2018-12-31&order-by=newest&page-size=100&q=Bitcoin&api-key=test\n",
            "Número de artigos utilizados: 72\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "the_guardian_2018_bitcoin_entities = extract_entities(the_guardian_2018_bitcoin_articles_url, print_all=False)"
      ],
      "metadata": {
        "id": "0secBbKuM2JJ"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "the_guardian_2018_bitcoin_network_df = get_network_data(the_guardian_2018_bitcoin_entities)\n",
        "\n",
        "G_the_guardian_2018_bitcoin = nx.from_pandas_edgelist(the_guardian_2018_bitcoin_network_df)\n",
        "\n",
        "G_the_guardian_2018_bitcoin.remove_edges_from(nx.selfloop_edges(G_the_guardian_2018_bitcoin))"
      ],
      "metadata": {
        "id": "Iu4zEkKBOACC"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(G_the_guardian_2018_bitcoin)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YPLtb2LFN6W",
        "outputId": "3099efed-ff05-46c4-fe83-33d3e50cbcb8"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Graph with 579 nodes and 606 edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "draw_ego_graph(G_the_guardian_2018_bitcoin, 'Bitcoin', file_path=\"2018_ego_bitcoin_graph.svg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "YZWTq-1POhj2",
        "outputId": "c392efe3-7938-4a4b-e914-d97e916f47a3"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1189.373954174957\" height=\"540\">\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 537 114 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 473 396 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 224 441 155 463\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 224 441 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 720 285 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 343 39 427 48\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 343 39 292 114\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 343 39 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 100 371 121 299\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 100 371 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 473 396 481 445\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 246 240 444 211\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 246 240 292 114\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 246 240 121 299\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 246 240 352 342\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 246 240 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 292 114 304 201\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 292 114 427 48\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 292 114 343 39\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 292 114 246 240\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 292 114 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 246 240 304 201\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 473 396 352 342\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 473 396 376 454\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 473 396 581 433\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 444 211 246 240\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 444 211 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 545 39 427 48\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 545 39 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 355 520 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 304 201 444 211\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 304 201 246 240\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 304 201 292 114\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 304 201 352 342\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 304 201 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 615 245 444 211\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 615 245 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 427 48 545 39\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 427 48 343 39\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 427 48 292 114\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 427 48 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 581 433 473 396\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 581 433 481 445\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 581 433 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 376 454 473 396\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 376 454 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 155 463 224 441\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 155 463 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 676 367 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 121 299 100 371\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 224 441\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 720 285\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 343 39\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 100 371\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 246 240\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 292 114\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 155 463\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 676 367\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 121 299\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 20 267\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 603 167\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 352 342\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 689 133\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 118 99\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 481 445\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 246 20\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 60 177\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 537 114\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 246 20 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 60 177 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 537 114 603 167\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 473 396\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 444 211 615 245\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 376 454\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 427 48\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 121 299 246 240\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 121 299 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 20 267 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 603 167 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 603 167 537 114\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 352 342 304 201\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 352 342 473 396\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 352 342 246 240\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 352 342 481 445\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 352 342 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 689 133 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 118 99 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 481 445 581 433\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 481 445 473 396\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 481 445 352 342\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 481 445 379 263\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 444 211\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 545 39\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 355 520\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 304 201\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 615 245\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 379 263 581 433\"/>\n<path stroke-width=\"0.1\" stroke=\"gray\" d=\"M 444 211 304 201\"/>\n<circle cx=\"537\" cy=\"114\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"60\" cy=\"177\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"246\" cy=\"20\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"379\" cy=\"263\" r=\"3.0\" style=\"fill:rgb(179, 3, 38);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"481\" cy=\"445\" r=\"3.0\" style=\"fill:rgb(86, 115, 224);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"118\" cy=\"99\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"689\" cy=\"133\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"352\" cy=\"342\" r=\"3.0\" style=\"fill:rgb(96, 128, 232);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"603\" cy=\"167\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"20\" cy=\"267\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"121\" cy=\"299\" r=\"3.0\" style=\"fill:rgb(76, 102, 214);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"676\" cy=\"367\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"155\" cy=\"463\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"292\" cy=\"114\" r=\"3.0\" style=\"fill:rgb(96, 128, 232);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"246\" cy=\"240\" r=\"3.0\" style=\"fill:rgb(105, 139, 239);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"100\" cy=\"371\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"343\" cy=\"39\" r=\"3.0\" style=\"fill:rgb(76, 102, 214);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"720\" cy=\"285\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"224\" cy=\"441\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"473\" cy=\"396\" r=\"3.0\" style=\"fill:rgb(99, 131, 234);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"376\" cy=\"454\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"581\" cy=\"433\" r=\"3.0\" style=\"fill:rgb(76, 102, 214);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"427\" cy=\"48\" r=\"3.0\" style=\"fill:rgb(88, 118, 226);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"615\" cy=\"245\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"304\" cy=\"201\" r=\"3.0\" style=\"fill:rgb(96, 128, 232);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"355\" cy=\"520\" r=\"3.0\" style=\"fill:rgb(58, 76, 192);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"545\" cy=\"39\" r=\"3.0\" style=\"fill:rgb(66, 88, 202);stroke:black;stroke-width:1.0\"/>\n<circle cx=\"444\" cy=\"211\" r=\"3.0\" style=\"fill:rgb(86, 115, 224);stroke:black;stroke-width:1.0\"/>\n<text text-anchor=\"start\" x=\"543\" y=\"114\" font-size=\"12\">New York</text><text text-anchor=\"start\" x=\"66\" y=\"177\" font-size=\"12\">Blockstack</text><text text-anchor=\"start\" x=\"252\" y=\"20\" font-size=\"12\">Marmite</text><text text-anchor=\"start\" x=\"385\" y=\"263\" font-size=\"12\">Bitcoin</text><text text-anchor=\"start\" x=\"487\" y=\"445\" font-size=\"12\">Ripple</text><text text-anchor=\"start\" x=\"124\" y=\"99\" font-size=\"12\">Proofpoint</text><text text-anchor=\"start\" x=\"695\" y=\"133\" font-size=\"12\">Blockchain, Ethereum   Smart Contractsby</text><text text-anchor=\"start\" x=\"358\" y=\"342\" font-size=\"12\">Russia</text><text text-anchor=\"start\" x=\"609\" y=\"167\" font-size=\"12\">Steven Englander</text><text text-anchor=\"start\" x=\"26\" y=\"267\" font-size=\"12\">Bitstamp</text><text text-anchor=\"start\" x=\"127\" y=\"299\" font-size=\"12\">the International Monetary Fund</text><text text-anchor=\"start\" x=\"682\" y=\"367\" font-size=\"12\">Michael Goldstein</text><text text-anchor=\"start\" x=\"161\" y=\"463\" font-size=\"12\">Luxembourg</text><text text-anchor=\"start\" x=\"298\" y=\"114\" font-size=\"12\">South Korea</text><text text-anchor=\"start\" x=\"252\" y=\"240\" font-size=\"12\">US</text><text text-anchor=\"start\" x=\"106\" y=\"371\" font-size=\"12\">Christine Lagarde</text><text text-anchor=\"start\" x=\"349\" y=\"39\" font-size=\"12\">Axel Weber</text><text text-anchor=\"start\" x=\"726\" y=\"285\" font-size=\"12\">CFD</text><text text-anchor=\"start\" x=\"230\" y=\"441\" font-size=\"12\">Bitstamp exchange</text><text text-anchor=\"start\" x=\"479\" y=\"396\" font-size=\"12\">Ethereum</text><text text-anchor=\"start\" x=\"382\" y=\"454\" font-size=\"12\">Unicef</text><text text-anchor=\"start\" x=\"587\" y=\"433\" font-size=\"12\">Monero</text><text text-anchor=\"start\" x=\"433\" y=\"48\" font-size=\"12\">UBS</text><text text-anchor=\"start\" x=\"621\" y=\"245\" font-size=\"12\">UK</text><text text-anchor=\"start\" x=\"310\" y=\"201\" font-size=\"12\">China</text><text text-anchor=\"start\" x=\"361\" y=\"520\" font-size=\"12\">Iceland</text><text text-anchor=\"start\" x=\"551\" y=\"39\" font-size=\"12\">Warren Buffett</text><text text-anchor=\"start\" x=\"450\" y=\"211\" font-size=\"12\">IMF</text></svg>"
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting graphs to use in Gephi"
      ],
      "metadata": {
        "id": "6lA986GsXjRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "def analyze_and_export_graph(graph, output_filename):\n",
        "    \"\"\"\n",
        "    Perform centrality analysis, k-core/k-shell decomposition, and export the graph.\n",
        "\n",
        "    Parameters:\n",
        "    graph (networkx.Graph): The input graph to analyze.\n",
        "    output_filename (str): The name of the output GEXF file.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Create a copy of the graph to work on\n",
        "    graph = graph.copy()\n",
        "\n",
        "    # Update node attributes for Gephi compatibility\n",
        "    for node, data in graph.nodes(data=True):\n",
        "        data[\"id\"] = node  # Unique identifier for each node\n",
        "        data[\"label\"] = node  # Label for visualization\n",
        "\n",
        "    # Calculate centrality measures\n",
        "    betweenness_centrality = nx.betweenness_centrality(graph)\n",
        "    nx.set_node_attributes(graph, betweenness_centrality, 'betweenness_centrality')\n",
        "\n",
        "    degree_centrality = nx.degree_centrality(graph)\n",
        "    nx.set_node_attributes(graph, degree_centrality, 'degree_centrality')\n",
        "\n",
        "    closeness_centrality = nx.closeness_centrality(graph)\n",
        "    nx.set_node_attributes(graph, closeness_centrality, 'closeness_centrality')\n",
        "\n",
        "    eigenvector_centrality = nx.eigenvector_centrality(graph)\n",
        "    nx.set_node_attributes(graph, eigenvector_centrality, 'eigenvector_centrality')\n",
        "\n",
        "    # Remove self-loops from the graph\n",
        "    graph.remove_edges_from(nx.selfloop_edges(graph))\n",
        "\n",
        "    # Calculate k-core and k-shell decomposition\n",
        "    n_cores = sorted(set(nx.core_number(graph).values()))\n",
        "\n",
        "    if len(n_cores) > 1:\n",
        "        k_shell = nx.k_shell(graph, k=n_cores[-2])  # Second-highest k-shell\n",
        "        k_core = nx.k_core(graph, k=n_cores[-1])  # Highest k-core\n",
        "    else:\n",
        "        raise ValueError(\"The network has only one k-core level.\")\n",
        "\n",
        "    # Mark nodes based on k-core and k-shell\n",
        "    nx.set_node_attributes(graph, 0, 'is_core')  # Default value for nodes outside k-core/shell\n",
        "    nx.set_node_attributes(graph, {n: 1 for n in k_core.nodes()}, 'is_core')  # Mark k-core nodes\n",
        "    nx.set_node_attributes(graph, {n: 2 for n in k_shell.nodes()}, 'is_core')  # Mark k-shell nodes\n",
        "\n",
        "    # Print k-core and k-shell information\n",
        "    print(f\"k-core/k-shell list: {n_cores}\")\n",
        "    print(f\"k-shell info for k = {n_cores[-2]}: {k_shell}\")\n",
        "    print(f\"k-core info for k = {n_cores[-1]}: {k_core}\")\n",
        "\n",
        "    # Export the graph to a GEXF file\n",
        "    nx.write_gexf(graph, output_filename)\n",
        "    print(f\"Graph exported to {output_filename}\\n\")"
      ],
      "metadata": {
        "id": "kWlA0s38Xi6V"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_and_export_graph(G_the_guardian_bitcoin, 'latest_bitcoin_network.gexf')\n",
        "analyze_and_export_graph(G_the_guardian_2018_bitcoin, '2018_bitcoin_network.gexf')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTI9svwVYs_o",
        "outputId": "81d8b111-c0cc-42a3-d29c-072b631b8b84"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-core/k-shell list: [1, 2, 3, 4, 5, 6]\n",
            "k-shell info for k = 5: Graph with 17 nodes and 32 edges\n",
            "k-core info for k = 6: Graph with 10 nodes and 36 edges\n",
            "Graph exported to latest_bitcoin_network.gexf\n",
            "\n",
            "k-core/k-shell list: [1, 2, 3, 4]\n",
            "k-shell info for k = 3: Graph with 25 nodes and 57 edges\n",
            "k-core info for k = 4: Graph with 5 nodes and 10 edges\n",
            "Graph exported to 2018_bitcoin_network.gexf\n",
            "\n"
          ]
        }
      ]
    }
  ]
}